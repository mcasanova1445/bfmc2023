{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px # this is another plotting library for interactive plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, manifold # we will use the metrics and manifold learning modules from scikit-learn\n",
    "from pathlib import Path # to interact with file paths\n",
    "from PIL import Image # to interact with images\n",
    "from tqdm import tqdm # progress bar\n",
    "from pprint import pprint # pretty print (useful for a more readable print of objects like lists or dictionaries)\n",
    "from IPython.display import clear_output # to clear the output of the notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROL\n",
    "# TODO : change the type yaws: use directly the y position or use the yaws relative to car position not relative to each other.\n",
    "num_channels = 1\n",
    "SIZE = (32,32)\n",
    "model_name = 'models/local_path_estimator.pt'\n",
    "onnx_local_path_estimator_path = \"models/local_path_estimator.onnx\"\n",
    "max_load = 15_000 #note: it will be ~50% more since training points with pure road gets flipped with inverted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Net and create Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK ARCHITECTURE\n",
    "\n",
    "class LocalPathEstimator(nn.Module):\n",
    "    def __init__(self, out_dim=4, channels=1): \n",
    "        super().__init__()\n",
    "        ### Convoluational layers\n",
    "        self.conv = nn.Sequential( #in = (SIZE)\n",
    "            nn.Conv2d(channels, 8, kernel_size=5, stride=1), #out = 30\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #out=15\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 8, kernel_size=5, stride=1), #out = 12\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1), #out=11\n",
    "            # nn.BatchNorm2d(4),\n",
    "            nn.Conv2d(8, 8, kernel_size=7, stride=1), #out = 6\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.flat = nn.Flatten()\n",
    "        ### Linear sections\n",
    "        self.lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=3*3*8, out_features=128),\n",
    "            # nn.ReLU(True),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=64, out_features=out_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flat(x)\n",
    "    \n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "local_path_estimator = LocalPathEstimator(out_dim=5,channels=num_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32, 32])\n",
      "out shape: torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "# TEST NET INPUTS/OUTPUTS\n",
    "#show the image with opencv\n",
    "img = cv.imread('tests/test_img.jpg')\n",
    "img = cv.resize(img, SIZE)\n",
    "if num_channels == 1:\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "#convert to tensor\n",
    "img = torch.from_numpy(img).float()\n",
    "img = img.permute(2,0,1)\n",
    "#add dimension\n",
    "img = img.unsqueeze(0).to(device)\n",
    "print(img.shape)\n",
    "\n",
    "local_path_estimator.eval()\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    output = local_path_estimator(img)\n",
    "    print(f'out shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG LOADER AND AUGMENTATION\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_and_augment_img(img, folder='training_imgs'):\n",
    "    # img = cv.imread(os.path.join(folder, f'img_{i+1}.png'))\n",
    "\n",
    "    #convert to gray\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    #create random ellipses to simulate light from the sun\n",
    "    light = np.zeros(img.shape, dtype=np.uint8)\n",
    "    #add ellipses\n",
    "    for j in range(2):\n",
    "        cent = (np.random.randint(0, img.shape[0]), np.random.randint(0, img.shape[1]))\n",
    "        axes_length = (np.random.randint(10, 50), np.random.randint(50, 300))\n",
    "        angle = np.random.randint(0, 360)\n",
    "        light = cv.ellipse(light, cent, axes_length, angle, 0, 360, 255, -1)\n",
    "    #create an image of random white and black pixels\n",
    "    light = cv.blur(light, (100,100))\n",
    "    noise = np.random.randint(0, 2, size=img.shape, dtype=np.uint8)*255\n",
    "    light = cv.subtract(light, noise)\n",
    "    light = 5 * light\n",
    "\n",
    "    #add light to the image\n",
    "    img = cv.add(img, light)\n",
    "\n",
    "    # cv.imshow('light', light)\n",
    "    # if cv.waitKey(0) == ord('q'):\n",
    "    #     break\n",
    "\n",
    "    #blur the image\n",
    "    img = cv.blur(img, (9,9))\n",
    "\n",
    "    # cut the top third of the image, let it 640x320\n",
    "    img = img[int(img.shape[0]/4):,:] ################################# /3\n",
    "    # assert img.shape == (320,640), f'img shape cut = {img.shape}'\n",
    "    #resize \n",
    "    img = cv.resize(img, SIZE)\n",
    "\n",
    "    #add random tilt\n",
    "    max_offset = 5\n",
    "    offset = np.random.randint(-max_offset, max_offset)\n",
    "    img = np.roll(img, offset, axis=0)\n",
    "    if offset > 0:\n",
    "        img[:offset, :] = np.random.randint(0,255)\n",
    "    elif offset < 0:\n",
    "        img[offset:, :] = np.random.randint(0,255)\n",
    "\n",
    "    #reduce contrast\n",
    "    const = np.random.uniform(0.1,1.2)\n",
    "    if np.random.uniform() > 5:\n",
    "        const = const*0.2\n",
    "    img = 127*(1-const) + img*const\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    #add noise \n",
    "    std = 150\n",
    "    std = np.random.randint(1, std)\n",
    "    noisem = np.random.randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.subtract(img, noisem)\n",
    "    noisep = np.random.randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.add(img, noisep)\n",
    "    #blur \n",
    "    img = cv.blur(img, (np.random.randint(1,3),np.random.randint(1,3)))\n",
    "\n",
    "    #add random brightness\n",
    "    max_brightness = 50\n",
    "    brightness = np.random.randint(-max_brightness, max_brightness)\n",
    "    if brightness > 0:\n",
    "        img = cv.add(img, brightness)\n",
    "    elif brightness < 0:\n",
    "        img = cv.subtract(img, -brightness)\n",
    "    \n",
    "    # # invert color\n",
    "    # if np.random.uniform(0, 1) > 0.6:\n",
    "    #     img = cv.bitwise_not(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "cv.namedWindow('img', cv.WINDOW_NORMAL)\n",
    "# cv.setWindowProperty('img', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)\n",
    "\n",
    "for i in range(500):\n",
    "    img = cv.imread(os.path.join('training_imgs', f'img_{i+1}.png'))\n",
    "    img = load_and_augment_img(img)\n",
    "    cv.imshow('img', img)\n",
    "    key = cv.waitKey(100)\n",
    "    if key == ord('q') or key == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET CLASS\n",
    "class CsvDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None, max_load=1000, channels=3):\n",
    "        self.transform = transform\n",
    "        self.folder = folder\n",
    "        self.data = []\n",
    "        self.channels = channels\n",
    "\n",
    "        #classification label for road ahead = 1,0,0,0,1,0,0,0,0,0,0,0,0,0,0\n",
    "        road_images_indexes = []\n",
    "        tot_lines = 0\n",
    "        with open(folder+'/classification_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            tot_lines = len(lines)\n",
    "            for i,line in enumerate(lines):\n",
    "                if line == '1,0,0,0,1,0,0,0,0,0,0,0,0,0,0':\n",
    "                    road_images_indexes.append(i)\n",
    "        print(f'total pure road images: {len(road_images_indexes)}')\n",
    "        road_imgs_mask = np.zeros(tot_lines, dtype=np.bool)\n",
    "        road_imgs_mask[road_images_indexes] = True\n",
    "\n",
    "        with open(folder+'/regression_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            # Get x and y values from each line and append to self.data\n",
    "            max_load = min(max_load, len(lines))\n",
    "            # self.all_imgs = torch.zeros((2*max_load, SIZE[1], SIZE[0], channels), dtype=torch.uint8) #adding flipped img\n",
    "            self.all_imgs = torch.zeros((max_load, SIZE[1], SIZE[0], channels), dtype=torch.uint8)\n",
    "\n",
    "            # road images specifically are added again along with their flipped image and label\n",
    "            road_imgs = torch.zeros((2*len(road_images_indexes), SIZE[1], SIZE[0], channels), dtype=torch.uint8)\n",
    "            road_labels = []\n",
    "\n",
    "            cv.namedWindow('img', cv.WINDOW_NORMAL)\n",
    "            # cv.setWindowProperty('img', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)\n",
    "            road_idx = 0\n",
    "            all_img_idx = 0\n",
    "            for i in tqdm(range(max_load)):\n",
    "\n",
    "                #label\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                #keep only info related to the lane, discard distance from stop line \n",
    "                sample = [sample[4], sample[5], sample[6], sample[7], sample[8]] # Sequence of yaws ahead\n",
    "                reg_label = np.array([float(s) for s in sample], dtype=np.float32)\n",
    "\n",
    "                #img \n",
    "                img = cv.imread(os.path.join(folder, f'img_{i+1}.png'))\n",
    "\n",
    "                #check if its in the road images\n",
    "                if road_imgs_mask[i]:\n",
    "                    img_r = load_and_augment_img(img.copy())\n",
    "                    # cv.imshow('imgR', img_r)\n",
    "                    img_r = img_r[:,:,np.newaxis]\n",
    "\n",
    "                    img_l = cv.flip(img, 1)\n",
    "                    img_l = load_and_augment_img(img_l)\n",
    "                    # cv.imshow('imgL', img_l)\n",
    "                    img_l = img_l[:,:,np.newaxis]\n",
    "                    # cv.waitKey(1)\n",
    "\n",
    "                    road_imgs[2*road_idx] = torch.from_numpy(img_r)\n",
    "                    road_imgs[2*road_idx+1] = torch.from_numpy(img_l)\n",
    "                    road_labels.append(reg_label)\n",
    "                    road_labels.append(-reg_label)\n",
    "                    road_idx += 1\n",
    "\n",
    "                else:\n",
    "                    img = load_and_augment_img(img)\n",
    "                    if i < 100:\n",
    "                        cv.imshow('img', img)\n",
    "                        cv.waitKey(1)\n",
    "                        if i == 99:\n",
    "                            cv.destroyAllWindows()\n",
    "                    #add a dimension to the image\n",
    "                    img = img[:, :,np.newaxis]\n",
    "                    self.all_imgs[all_img_idx] = torch.from_numpy(img)\n",
    "                    self.data.append(reg_label)\n",
    "                    all_img_idx += 1\n",
    "\n",
    "            #cut imgs to the right length\n",
    "            road_imgs = road_imgs[:2*road_idx]\n",
    "            self.all_imgs = self.all_imgs[:all_img_idx]\n",
    "\n",
    "            #concatenate all_imgs and road_imgs\n",
    "            print(f'road images: {road_imgs.shape}')\n",
    "            print(f'all images: {self.all_imgs.shape}')\n",
    "            self.all_imgs = torch.cat((self.all_imgs, road_imgs), dim=0)\n",
    "            print(f'self.data shape: {len(self.data)}')\n",
    "            print(f'road_labels shape = {len(road_labels)}')\n",
    "            self.data = np.concatenate((np.array(self.data), np.array(road_labels)), axis=0)\n",
    "\n",
    "            print(f'\\nall imgs: {self.all_imgs.shape}')\n",
    "            print(f'data: {self.data.shape}')\n",
    "\n",
    "            #free road_imgs from memory\n",
    "            del road_imgs\n",
    "            del road_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img = read_image(os.path.join(self.folder, f'img_{idx+1}.png'))\n",
    "        # img = img.float()\n",
    "        img = self.all_imgs[idx]\n",
    "        img = img.permute(2, 0, 1).float()\n",
    "        value = self.data[idx]\n",
    "        return img, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total pure road images: 46902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:53<00:00, 86.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "road images: torch.Size([17172, 32, 32, 1])\n",
      "all images: torch.Size([6414, 32, 32, 1])\n",
      "self.data shape: 6414\n",
      "road_labels shape = 17172\n",
      "\n",
      "all imgs: torch.Size([23586, 32, 32, 1])\n",
      "data: (23586, 5)\n"
     ]
    }
   ],
   "source": [
    "#create dataset #takes a long time but then training is faster\n",
    "train_dataset = CsvDataset('training_imgs', max_load=max_load, channels=num_channels)\n",
    "#split dataset into train and val\n",
    "train_size = int(0.9*len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4096, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 1, 32, 32])\n",
      "torch.Size([4096, 5])\n"
     ]
    }
   ],
   "source": [
    "#test dataloader\n",
    "sample = next(iter(train_dataloader))\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING FUNCTION\n",
    "def train_epoch(model, dataloader, regr_loss_fn, optimizer, discount=0.9, L1_lambda=0.0, L2_lambda=0.0,  device=device):\n",
    "    # Set the model to training mode\n",
    "    model.train() #train\n",
    "    # Initialize the loss\n",
    "    losses0, losses1, losses2, losses3, losses4 = [], [], [], [], []\n",
    "\n",
    "    # Loop over the training batches\n",
    "    for (input, regr_label) in tqdm(dataloader):\n",
    "        # Move the input and target data to the selected device\n",
    "        input, regr_label =input.to(device), regr_label.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the output\n",
    "        output = model(input)\n",
    "\n",
    "        #regression\n",
    "        y0 = output[:,0]\n",
    "        y1 = output[:,1]\n",
    "        y2 = output[:,2]\n",
    "        y3 = output[:,3]\n",
    "        y4 = output[:,4]\n",
    "\n",
    "        l0 = regr_label[:, 0]\n",
    "        l1 = regr_label[:, 1]\n",
    "        l2 = regr_label[:, 2]\n",
    "        l3 = regr_label[:, 3]\n",
    "        l4 = regr_label[:, 4]\n",
    "\n",
    "        # Compute the losses\n",
    "        loss0 = discount**0 * regr_loss_fn(y0, l0)\n",
    "        loss1 = discount**1 * regr_loss_fn(y1, l1)\n",
    "        loss2 = discount**2 * regr_loss_fn(y2, l2)\n",
    "        loss3 = discount**3 * regr_loss_fn(y3, l3)\n",
    "        loss4 = discount**4 * regr_loss_fn(y4, l4)\n",
    "\n",
    "        #L1 regularization\n",
    "        L1_norm = sum(p.abs().sum() for p in model.conv.parameters())\n",
    "        L1_loss = L1_lambda * L1_norm \n",
    "        #L2 regularization\n",
    "        L2_norm = sum(p.pow(2).sum() for p in model.conv.parameters())\n",
    "        L2_loss = L2_lambda * L2_norm\n",
    "\n",
    "        loss = L1_loss + L2_loss + loss0 + loss1 + loss2 + loss3 + loss4\n",
    "\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #batch loss\n",
    "        losses0.append(loss0.item())\n",
    "        losses1.append(loss1.item())\n",
    "        losses2.append(loss2.item())\n",
    "        losses3.append(loss3.item())\n",
    "        losses4.append(loss4.item())\n",
    "\n",
    "    # Return the average training loss\n",
    "    return np.mean(losses0), np.mean(losses1), np.mean(losses2), np.mean(losses3), np.mean(losses4)\n",
    "\n",
    "    # VALIDATION FUNCTION\n",
    "def val_epoch(local_path_estimator, val_dataloader, regr_loss_fn, device=device):\n",
    "    local_path_estimator.eval()\n",
    "\n",
    "    losses0, losses1, losses2, losses3, losses4 = [], [], [], [], []\n",
    "\n",
    "    # curv_losses = []\n",
    "    for (input, regr_label) in tqdm(val_dataloader):\n",
    "        input, regr_label =input.to(device), regr_label.to(device)\n",
    "        output = local_path_estimator(input)\n",
    "\n",
    "        y0 = output[:,0]\n",
    "        y1 = output[:,1]\n",
    "        y2 = output[:,2]\n",
    "        y3 = output[:,3]\n",
    "        y4 = output[:,4]\n",
    "\n",
    "        l0 = regr_label[:, 0]\n",
    "        l1 = regr_label[:, 1]\n",
    "        l2 = regr_label[:, 2]\n",
    "        l3 = regr_label[:, 3]\n",
    "        l4 = regr_label[:, 4]\n",
    "\n",
    "        loss0 = regr_loss_fn(y0, l0)\n",
    "        loss1 = regr_loss_fn(y1, l1)\n",
    "        loss2 = regr_loss_fn(y2, l2)\n",
    "        loss3 = regr_loss_fn(y3, l3)\n",
    "        loss4 = regr_loss_fn(y4, l4)\n",
    "\n",
    "        losses0.append(loss0.item())\n",
    "        losses1.append(loss1.item())\n",
    "        losses2.append(loss2.item())\n",
    "        losses3.append(loss3.item())\n",
    "        losses4.append(loss4.item())\n",
    "\n",
    "    return np.mean(losses0), np.mean(losses1), np.mean(losses2), np.mean(losses3), np.mean(losses4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  60/60\n",
      "Train loss: 0.0391 - 0.0556 - 0.0782 - 0.1087 - 0.1468\n",
      "Val loss:   0.0474 - 0.0757 - 0.1125 - 0.1609 - 0.2252\n"
     ]
    }
   ],
   "source": [
    "# TRAINING \n",
    "#parameters\n",
    "lr = 0.001 #0.005\n",
    "epochs = 60\n",
    "discount_factor = 0.95\n",
    "#regularization is applied only to convolutional section, add weight decay to apply it to all layers\n",
    "L1_lambda = 0.0 #1e-4\n",
    "L2_lambda = 0.0 #1e-2\n",
    "optimizer = torch.optim.Adam(local_path_estimator.parameters(), lr=lr, weight_decay=9e-5) #wd = 2e-3# 9e-5\n",
    "\n",
    "regr_loss_fn = nn.MSELoss()\n",
    "for epoch in range(epochs):\n",
    "    try:\n",
    "    # if True:\n",
    "        l0,l1,l2,l3,l4 = train_epoch(local_path_estimator, train_dataloader, regr_loss_fn, optimizer, discount_factor, L1_lambda, L2_lambda, device)\n",
    "        v0,v1,v2,v3,v4 = val_epoch(local_path_estimator, val_dataloader, regr_loss_fn, device)\n",
    "        clear_output(wait=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        torch.cuda.empty_cache()\n",
    "        continue\n",
    "    print(f'Epoch  {epoch+1}/{epochs}')\n",
    "    print(f'Train loss: {l0:.4f} - {l1:.4f} - {l2:.4f} - {l3:.4f} - {l4:.4f}')\n",
    "    print(f'Val loss:   {v0:.4f} - {v1:.4f} - {v2:.4f} - {v3:.4f} - {v4:.4f}')\n",
    "    torch.save(local_path_estimator.state_dict(), model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 164.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.0472 - 0.0755 - 0.1125 - 0.1610 - 0.2260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE ON TEST SET (UNSEEN DATA)\n",
    "local_path_estimator.load_state_dict(torch.load(model_name))\n",
    "v0,v1,v2,v3,v4 = val_epoch(local_path_estimator, val_dataloader, regr_loss_fn, device)\n",
    "\n",
    "print(f'Val loss:   {v0:.4f} - {v1:.4f} - {v2:.4f} - {v3:.4f} - {v4:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1, 5, 5)\n",
      "(8, 8, 5, 5)\n",
      "(8, 8, 7, 7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x1440 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VISUALIZE CONVOLUTIONAL FILTERS\n",
    "conv_layers = []\n",
    "children = list(local_path_estimator.children())\n",
    "for i in range(len(children)):\n",
    "    if isinstance(children[i], nn.Conv2d):\n",
    "        conv_layers.append(children[i])\n",
    "    elif isinstance(children[i], nn.Sequential):\n",
    "        for child in children[i].children():\n",
    "            if isinstance(child, nn.Conv2d):\n",
    "                conv_layers.append(child)\n",
    "\n",
    "c0 = conv_layers[0].weight.data.cpu().numpy()\n",
    "c1 = conv_layers[1].weight.data.cpu().numpy()\n",
    "c2 = conv_layers[2].weight.data.cpu().numpy()\n",
    "\n",
    "def plot_nchw_data(data, h_num, v_num, title, size=(10, 10)):\n",
    "    fig, axs = plt.subplots(h_num, v_num, figsize=size)\n",
    "    shape = data.shape\n",
    "    data = data.reshape(shape[0]*shape[1], shape[2], shape[3])\n",
    "    for idx, ax in enumerate(axs.flatten()):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if idx < len(data):\n",
    "            ax.imshow(data[idx,:,:], cmap='gray')\n",
    "    plt.suptitle(title)\n",
    "    #plt.tight_layout(rect=[0, 0, 1, 0.97], h_pad=0, w_pad=0)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# fig0 = plot_nchw_data(c0, 4, 4, 'conv0')\n",
    "print(c0.shape)\n",
    "print(c1.shape)\n",
    "print(c2.shape)\n",
    "\n",
    "fig0 = plot_nchw_data(c0, 2, 4, 'conv0', size=(10,5))\n",
    "\n",
    "fig1 = plot_nchw_data(c1, 8, 4, 'conv1', size=(10,20)) \n",
    "\n",
    "fig2 = plot_nchw_data(c2, 4, 4, 'conv2', size=(10,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocalPathEstimator(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Conv2d(8, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "  )\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=72, out_features=128, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=64, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT TO ONNX MODEL FOR OPENCV\n",
    "local_path_estimator.load_state_dict(torch.load(model_name))\n",
    "\n",
    "#save the model so that opencv can load it\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "device = torch.device('cpu')\n",
    "local_path_estimator.to(device)\n",
    "\n",
    "# set the model to inference mode\n",
    "local_path_estimator.eval()\n",
    "\n",
    "# Create some sample input in the shape this model expects \n",
    "# This is needed because the convertion forward pass the network once \n",
    "dummy_input = torch.randn(1, num_channels, SIZE[1], SIZE[0])\n",
    "torch.onnx.export(local_path_estimator, dummy_input, onnx_local_path_estimator_path, verbose=True)\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "local_path_estimator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 3243.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0.47992128 0.67809755 0.88718575 0.9531509  1.0173134 ]]\n",
      "Predictions shape: (1, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST WITH OPENCV\n",
    "sample_image = \"training_imgs/img_1.png\"\n",
    "images = [cv.imread(f\"training_imgs/img_{i+1}.png\") for i in range(100)]\n",
    " \n",
    "#The Magic:\n",
    "lk =  cv.dnn.readNetFromONNX(onnx_local_path_estimator_path) \n",
    "\n",
    "avg_col = (0,0,0) if num_channels == 3 else 0\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    image = images[i]\n",
    "    image = cv.resize(image, SIZE)\n",
    "    if num_channels == 1:\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    blob = cv.dnn.blobFromImage(image, 1.0, SIZE, avg_col, swapRB=True, crop=False)\n",
    "    # print(blob.shape)\n",
    "    lk.setInput(blob)\n",
    "    preds = lk.forward()\n",
    "    # print(f\"Predictions: {preds[0][2]}\")\n",
    "\n",
    "print(f\"Predictions: {preds}\")\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee89b7c6bc96453738565335b56b694d8a30ac65e979633b683f8408c8233c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('dl_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
